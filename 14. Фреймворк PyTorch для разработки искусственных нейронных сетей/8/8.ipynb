{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "722d4855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from torchvision.utils import save_image, make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3e71f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01a0d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Использование таких словарей позволяет нам варьировать параметры нашей сети в процессе использования\n",
    "        self.activations = nn.ModuleDict([\n",
    "            ['lrelu', nn.LeakyReLU(0.2, inplace=True)],\n",
    "            ['relu', nn.ReLU()]\n",
    "        ])\n",
    "        \n",
    "        def block(in_feat, out_feat, normalize=True, activation='relu'):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]  # Если мы создаем последовательность слоев - то мы задаем их\n",
    "                                                     # с помощью списка.\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat))\n",
    "            layers.append(self.activations[activation])  # Эта строчка означает тоже самое что и\n",
    "                                                         # layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim, 128, normalize=False),  # Звездочка означает unpacking списка  \n",
    "            *block(128, 256, activation='lrelu'),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.reshape(-1, *img_shape)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5ac12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLinearLayer(nn.Module):\n",
    "    def __init__(self, size_in, size_out):\n",
    "        super().__init__()\n",
    "        self.size_in, self.size_out = size_in, size_out\n",
    "        \n",
    "        weights = torch.Tensor(size_out, size_in)\n",
    "        self.weights = nn.Parameter(weights) # Обьявляем веса как параметры слоя\n",
    "\n",
    "        bias = torch.Tensor(size_out)\n",
    "        self.bias = nn.Parameter(bias)\n",
    "\n",
    "        nn.init.uniform_(self.weights, -0.005, 0.005) \n",
    "        nn.init.uniform_(self.bias, -0.005, 0.005)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        # По формуле линейного слоя, нам нужно умножить наши данные \n",
    "        # на транспонированные веса и добавить смещение\n",
    "        w_times_x = torch.mm(x, self.weights.t())\n",
    "        return torch.add(w_times_x, self.bias)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a74b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = CustomLinearLayer(1, 2)\n",
    "layer.weights, layer.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e088ef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            CustomLinearLayer(int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            CustomLinearLayer(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            CustomLinearLayer(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "  \n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.reshape(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4526f39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20  # количество эпох\n",
    "lr = 0.0002  # шаг обучения\n",
    "\n",
    "b1 = 0.5  # гиперпараметр для оптимайзера Adam\n",
    "b2 = 0.999  # гиперпараметр для оптимайзера Adam\n",
    "\n",
    "latent_dim = 100  # Размерность случайного вектора, который подается на вход генератору\n",
    "\n",
    "sample_interval = 500  # количество итераций для отображения процесса обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf5feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# Для каждой нейронки свой опитимизатор\n",
    "optimizer_G = torch.optim.Adam(\n",
    "    generator.parameters(),\n",
    "    lr=lr, \n",
    "    betas=(b1, b2)\n",
    ")\n",
    "optimizer_D = torch.optim.Adam(\n",
    "    discriminator.parameters(), \n",
    "    lr=lr, \n",
    "    betas=(b1, b2)\n",
    ")\n",
    "\n",
    "# Но вот функция ошибки у нас будет одна общая\n",
    "adversarial_loss = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d9700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_loss_history = []\n",
    "g_loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc187893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (imgs, labels) in enumerate(real_data):\n",
    "        \n",
    "##################### Лейблы для данных: 1 - настоящие, 0 - сгенерированные ########\n",
    "        valid = torch.FloatTensor(batch_size, 1).fill_(1.0).to(device)\n",
    "        fake = torch.FloatTensor(batch_size, 1).fill_(0.0).to(device)\n",
    "\n",
    "        real_imgs = imgs.type(torch.FloatTensor).to(device)\n",
    "\n",
    "        # Генерация шума\n",
    "        z = torch.FloatTensor(np.random.normal(0, 1, (batch_size, latent_dim))).to(device)\n",
    "        \n",
    "        # Генерируем данные Генератором на основе шума\n",
    "        gen_imgs = generator(z)\n",
    "        \n",
    "######################  Тренировка дискриминатора    ##########################\n",
    "        \n",
    "        # Получаем предсказания дискриминатора на основе реальных данных\n",
    "        real_pred = discriminator(real_imgs)\n",
    "        \n",
    "        # Тут сравниваем предсказанные значения Дискриминатора(на основе настоящих данных) с настоящими\n",
    "        d_real_loss = adversarial_loss(real_pred, valid)\n",
    "        \n",
    "        # Подаем сгенерированые данные на Дискриминатор \n",
    "        fake_pred = discriminator(gen_imgs)\n",
    "        \n",
    "        # расчитываем ошибку предсказанного с фейковыми лейблами\n",
    "        d_fake_loss = adversarial_loss(fake_pred, fake)\n",
    "        \n",
    "        # И усредняем два лосса в один\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "######################  Тренировка генератора    ##########################\n",
    "        \n",
    "        # генерация шума\n",
    "        z = torch.FloatTensor(np.random.normal(0, 1, (batch_size, latent_dim))).to(device)\n",
    "        \n",
    "        # Генерируем данные Генератором на основе шума\n",
    "        gen_imgs = generator(z)\n",
    "\n",
    "        # Подаем сгенерированые данные на Дискриминатор \n",
    "        fake_pred = discriminator(gen_imgs)\n",
    "    \n",
    "        # Тут сравниваем предсказанные значения Дискриминатора (на основе сгенерировнных данных) с настоящими\n",
    "        g_loss = adversarial_loss(fake_pred, valid)\n",
    "        \n",
    "        # Делаем шаг обучения нашего Генератора\n",
    "        optimizer_G.zero_grad()\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        \n",
    "######## Отображение процесса обучения и вывод функций потерь ############\n",
    "        batches_done = epoch * len(real_data) + i\n",
    "    \n",
    "        if batches_done % sample_interval == 0:\n",
    "            with torch.no_grad():\n",
    "                plt.clf()\n",
    "\n",
    "                display.clear_output(wait=False)\n",
    "                sample_image(gen_imgs)\n",
    "                print(f\"[Epoch {epoch}/{n_epochs}] [Batch {i}/{len(real_data)}]\", end='|')\n",
    "                print(f'[D loss: {d_loss.item()}] [G loss: {g_loss.item()}]') \n",
    "\n",
    "\n",
    "                # display.display(plt.gcf())\n",
    "                plt.show()\n",
    "                d_loss = d_loss.cpu().detach()\n",
    "                g_loss = g_loss.cpu().detach()\n",
    "\n",
    "\n",
    "                d_loss_history.append(d_loss)\n",
    "                g_loss_history.append(g_loss)\n",
    "\n",
    "                plt.plot(np.array(d_loss_history), label='D loss')\n",
    "                plt.plot(np.array(g_loss_history), label='G loss')\n",
    "                plt.legend()\n",
    "                plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a778b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c3f47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960fd98a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
